{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile 'Artigos.py'\n",
    "import os \n",
    "import json\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "class Artigos():\n",
    "    \n",
    "    def __init__(self, raiz = os.getcwd(), biblioteca=['esporte', 'politica', 'tecnologia']):\n",
    "        \n",
    "        self.raiz = raiz\n",
    "        self.biblioteca = biblioteca \n",
    "        nltk.download('stopwords')\n",
    "    \n",
    "        self.lista_stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "        self.lista_pontuacao = string.punctuation\n",
    "\n",
    "        \n",
    "        for assunto in biblioteca:\n",
    "            \n",
    "            caminho = os.path.join(self.raiz, assunto)\n",
    "            \n",
    "            if not os.path.isdir(caminho):\n",
    "            \n",
    "                os.mkdir(caminho)\n",
    "         \n",
    "    \n",
    "    def __retira_pontuacao__(self, texto='a vaca, é amarela!!! a a a'):\n",
    "       \n",
    "        for pontuacao in self.lista_pontuacao:\n",
    "            texto = texto.replace(pontuacao, '')\n",
    "        \n",
    "        return texto\n",
    "    \n",
    "    def __retira_stopwords__(self, texto = \"a vaca, é amarela!!!! a a a\"):\n",
    "    \n",
    "        lista_palavras = texto.split()\n",
    "        nova_lista_palavras = []\n",
    "    \n",
    "        for  palavra in lista_palavras:\n",
    "        \n",
    "            palavra = palavra.strip()\n",
    "        \n",
    "            eh_stopwords = palavra in self.lista_stopwords\n",
    "            na_lista = palavra in nova_lista_palavras\n",
    "            \n",
    "            if (not eh_stopwords) and (not na_lista):        \n",
    "                nova_lista_palavras.append(palavra)\n",
    "    \n",
    "        return nova_lista_palavras\n",
    "\n",
    "        \n",
    "    def __ajuste_titulo__(self, titulo):\n",
    "        return \"_\".join(titulo.split(' '))\n",
    "    \n",
    "    def __filtro_palavras__(self, texto='a vaca, é amarela!!! a a a'):\n",
    "        \n",
    "        texto_sem_pontuacao = self.__retira_pontuacao__(texto = texto)\n",
    "        lista_palavras = self.__retira_stopwords__(texto = texto_sem_pontuacao)\n",
    "    \n",
    "        return lista_palavras\n",
    "    \n",
    "    def adicionar_artigo(self, titulo, assunto, data, texto):\n",
    "        \n",
    "        if assunto not in self.biblioteca:\n",
    "            raise AssuntoNotFound\n",
    "            \n",
    "        novo_artigo = {}\n",
    "        \n",
    "        titulo = titulo.lower()\n",
    "        \n",
    "        titulo_sem_espacos = self.__ajuste_titulo__(titulo)\n",
    "        \n",
    "        novo_artigo['titulo'] = titulo\n",
    "        novo_artigo['data'] = data\n",
    "        novo_artigo['assunto'] = assunto\n",
    "        novo_artigo['texto'] = texto\n",
    "        \n",
    "        arquivo_json = json.dumps(novo_artigo, indent = 4)\n",
    "        \n",
    "        diretorio_novo_arquivo = os.path.join(self.raiz, assunto, titulo_sem_espacos + '.txt' )\n",
    "        \n",
    "        with open(diretorio_novo_arquivo, 'w') as arquivo:\n",
    "            arquivo.writelines(arquivo_json)\n",
    "        \n",
    "#         print(novo_artigo)\n",
    "        \n",
    "        \n",
    "    def consultar_por_data(self, reverse = False):\n",
    "        \"\"\"\n",
    "        Retorna uma lista contendo todos os artigos em ordem\n",
    "        \"\"\"\n",
    "        pacote = []\n",
    "        \n",
    "        for assunto in self.biblioteca:\n",
    "            \n",
    "            diretorio_assunto = os.path.join(self.raiz, assunto)\n",
    "\n",
    "            for artigo in os.listdir(diretorio_assunto):\n",
    "                \n",
    "                caminho_artigo = os.path.join(diretorio_assunto, artigo)\n",
    "               \n",
    "                if '.ipynb_checkpoints' not in caminho_artigo:\n",
    "                    \n",
    "                    with open(caminho_artigo, 'r') as arquivo_json:\n",
    "                        arquivo_dicionario = json.loads(arquivo_json.read())\n",
    "                        pacote.append(arquivo_dicionario)\n",
    "                                        \n",
    "        os.chdir(self.raiz)\n",
    "        api = sorted(pacote, key=lambda artigo: artigo['data'])\n",
    "        if reverse:\n",
    "            api.reverse()\n",
    "            return api\n",
    "        else:\n",
    "            return api\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testes da classe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### criação da classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\OneDrive\\Estudos\\UFPE\\2020.2\\Santander\\Santander coders\\Untitled Folder\\Classes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from Artigos import Artigos\n",
    "import os\n",
    "print(os.getcwd())\n",
    "raiz = os.getcwd()\n",
    "gerenciador = Artigos(raiz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adicionando um artigo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "raiz = os.getcwd()\n",
    "gerenciador = Artigos(raiz)\n",
    "gerenciador.adicionar_artigo('a vaca amarela34', 'esporte', '13/01/1999','a vaca amarela caminhou até a venda' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordenando por datas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "raiz = os.getcwd()\n",
    "gerenciador = Artigos(raiz)\n",
    "api = gerenciador.consultar_por_data(True)\n",
    "# print(api)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retirando pontuacao do texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "a vaca é amarela a a a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "gerenciador = Artigos(raiz)\n",
    "resultado = gerenciador.__retira_pontuacao__()\n",
    "print(resultado)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retirando stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "gerenciador = Artigos(raiz)\n",
    "texto = \"a vaca, é amarela!!!! a a a\"\n",
    "lista_palavras1 = gerenciador.__retira_stopwords__(texto)\n",
    "print(lista_palavras1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtrar palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vaca', 'amarela']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "gerenciador = Artigos()\n",
    "lista_palavras = gerenciador.__filtro_palavras__()\n",
    "print(lista_palavras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analisar relação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## retornar a porcentagem de um texto em relação ao outro\n",
    "# como ser feito?\n",
    "# utiliza filtrar_alavras em ambos os textos e em seguida verifica quantas palavras estão dentro do outro texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['estavamos', 'todos', 'dentro', 'casa']\n",
      "['estavamos', 'todos', 'dentro', 'rua', 'logo', 'seguida', 'cachorro', 'atacou']\n",
      "0.75\n",
      "0.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "gerenciador = Artigos()\n",
    "texto1 = 'estavamos todos dentro de casa'\n",
    "texto2 = 'estavamos todos dentro na rua, logo em seguida um cachorro nos atacou'\n",
    "\n",
    "lista_palavras1 = gerenciador.__filtro_palavras__(texto1)\n",
    "lista_palavras2 = gerenciador.__filtro_palavras__(texto2)\n",
    "print(lista_palavras1)\n",
    "print(lista_palavras2)\n",
    "\n",
    "resultado = list(filter(lambda palavra: palavra in lista_palavras2, lista_palavras1))\n",
    "porcentagem = len(resultado)/len(lista_palavras1)\n",
    "print(porcentagem)\n",
    "\n",
    "resultado2 = list(filter(lambda palavra: palavra in lista_palavras1, lista_palavras2))\n",
    "porcentagem2 = len(resultado2)/len(lista_palavras2)\n",
    "print(porcentagem2)\n",
    "\n",
    "\n",
    "def __relacao_entre_textos__(texto1, texto2):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
